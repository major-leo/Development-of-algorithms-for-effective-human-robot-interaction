{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a400d577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44f01fe76614bcfb9c09e5f0ce58375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record Audio', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47e0b43c38c4f43a392062cfcc72c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import Audio, display\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio(duration=5, fs=44100):\n",
    "    \"\"\"\n",
    "    Record audio for a given duration and sampling rate.\n",
    "    \"\"\"\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=2)\n",
    "    sd.wait()\n",
    "    return recording, fs\n",
    "\n",
    "# Button to handle recording\n",
    "record_button = widgets.Button(description=\"Record Audio\")\n",
    "\n",
    "# Output widget to display audio widget\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_record_button_clicked(b):\n",
    "    with output:\n",
    "        # Clear previous recordings\n",
    "        output.clear_output()\n",
    "        \n",
    "        # Record audio\n",
    "        recording, fs = record_audio(duration=5)  # Record for 5 seconds\n",
    "        \n",
    "        # Save the recording\n",
    "        sf.write('recording.wav', recording, fs)\n",
    "        \n",
    "        # Display audio widget\n",
    "        display(Audio('recording.wav', autoplay=False))\n",
    "\n",
    "# Link button click event to the function\n",
    "record_button.on_click(on_record_button_clicked)\n",
    "\n",
    "# Display button\n",
    "display(record_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafacebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized Text: testing testing 1 2 3 4 5 6 7\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load the recorded audio file\n",
    "audio_file_path = 'recording.wav'\n",
    "\n",
    "# Perform speech recognition\n",
    "with sr.AudioFile(audio_file_path) as source:\n",
    "    # Record the audio from the file\n",
    "    audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        # Convert speech to text\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(\"Recognized Text:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand the audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa31735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "def ask_chatgpt(question):\n",
    "    \"\"\"\n",
    "    Send a question to ChatGPT and return the response.\n",
    "    \"\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Assuming 'transcribed_text' contains your speech-to-text result\n",
    "gpt_response = ask_chatgpt(\"Hello ChatGPT\")\n",
    "print(gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792d2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
